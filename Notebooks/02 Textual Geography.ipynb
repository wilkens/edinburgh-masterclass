{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Textual geography \n",
    "\n",
    "This session will walk through some more advanced text processing and data wrangling to produce a map of the locations mentioned in our corpus. Topics covered include:\n",
    "\n",
    "* Named entity recognition using Stanford's CRF-NER package.\n",
    "* Geolocation using Google's mapping APIs.\n",
    "* Cartographic visualization, both static (for print publication) and interactive (for online use).\n",
    "\n",
    "## Named entity recognition\n",
    "\n",
    "There are several approaches to identifying the places used in a piece of text. We could rely on a dictionary or gazetteer, which would tell us that Edinburgh is a city in Scotland, but would also tell us that Charlotte BrÃ¶nte is a city in the United States.\n",
    "\n",
    "We'll instead use statistical machine learning methods. While we *will* get an intro to machine learning this afternoon, for now we'll rely on the [implementation by the Stanford NLP group](http://nlp.stanford.edu/software/CRF-NER.html).\n",
    "\n",
    "This is a Java package. It's possible -- with a lot of work -- to invoke Java code from Python. But there's no point in this case; it's much easier to invoke the NER package from the command line and to read in the plain text output.\n",
    "\n",
    "Note that there do exist NER, POS, and other NLP packages for Python. NLTK -- the Natural Language Tool Kit, which we met in the last notebook when we used it for corpus processing -- is one of the most diverse and well conceived. But it's not optimized for speed and isn't notably accurate compared to more production-oriented offerings. \n",
    "\n",
    "There's a guide to using the NER package on Stanford's site. Here's the short version, for reference:\n",
    "\n",
    "```\n",
    "java -mx1g -cp \"*:lib/*\" edu.stanford.nlp.ie.crf.CRFClassifier\n",
    "-loadClassifier classifiers/english.all.3class.distsim.crf.ser.gz \n",
    "-outputFormat tabbedEntities \n",
    "-textFile file.txt > file.tsv\n",
    "```\n",
    "\n",
    "This runs the English-language classifier over a single text file. Note that we need to have a classifier trained for the language of the text we're processing. Stanford has trained models for English, Spanish, German, Chinese, and other major languages, but they're lacking French and a great many other languages.\n",
    "\n",
    "The classidier's output follows a tabbed format that looks like this:\n",
    "\n",
    "```\n",
    "                Why did the poor poet of\n",
    "Tennessee       LOCATION        , upon suddenly receiving two handfuls of silver , deliberate whether to buy him a coat , which he sadly needed , or invest his money in a pedestrian trip to\n",
    "Rockaway Beach  LOCATION        ?\n",
    "```\n",
    "\n",
    "The thing to notice is that every line begins with two tabs, but only the text in front of the first tab is a recognized entity. The text in front of the second tab, then, indicates the type of entity: PERSON, ORGANIZATION, or LOCATION. Any text following the second tab is body text, presumed not to contain any named entities.\n",
    "\n",
    "So let's recreate our corpus, then read in the tagged files and get a list of the locations used in the corpus.\n",
    "\n",
    "### Recreate the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mwilkens/anaconda/envs/carto/lib/python3.5/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nation</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>pubdate</th>\n",
       "      <th>gender</th>\n",
       "      <th>wordcount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A-Cather-Antonia-1918-F</th>\n",
       "      <td>A</td>\n",
       "      <td>Cather</td>\n",
       "      <td>Antonia</td>\n",
       "      <td>1918</td>\n",
       "      <td>F</td>\n",
       "      <td>97574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-Chesnutt-Marrow-1901-M</th>\n",
       "      <td>A</td>\n",
       "      <td>Chesnutt</td>\n",
       "      <td>Marrow</td>\n",
       "      <td>1901</td>\n",
       "      <td>M</td>\n",
       "      <td>110288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-Crane-Maggie-1893-M</th>\n",
       "      <td>A</td>\n",
       "      <td>Crane</td>\n",
       "      <td>Maggie</td>\n",
       "      <td>1893</td>\n",
       "      <td>M</td>\n",
       "      <td>28628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-Davis-Life_Iron_mills-1861-F</th>\n",
       "      <td>A</td>\n",
       "      <td>Davis</td>\n",
       "      <td>Life Iron mills</td>\n",
       "      <td>1861</td>\n",
       "      <td>F</td>\n",
       "      <td>18789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-Dreiser-Sister_Carrie-1900-M</th>\n",
       "      <td>A</td>\n",
       "      <td>Dreiser</td>\n",
       "      <td>Sister Carrie</td>\n",
       "      <td>1900</td>\n",
       "      <td>M</td>\n",
       "      <td>194062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               nation    author            title  pubdate  \\\n",
       "file                                                                        \n",
       "A-Cather-Antonia-1918-F             A    Cather          Antonia     1918   \n",
       "A-Chesnutt-Marrow-1901-M            A  Chesnutt           Marrow     1901   \n",
       "A-Crane-Maggie-1893-M               A     Crane           Maggie     1893   \n",
       "A-Davis-Life_Iron_mills-1861-F      A     Davis  Life Iron mills     1861   \n",
       "A-Dreiser-Sister_Carrie-1900-M      A   Dreiser    Sister Carrie     1900   \n",
       "\n",
       "                               gender  wordcount  \n",
       "file                                              \n",
       "A-Cather-Antonia-1918-F             F      97574  \n",
       "A-Chesnutt-Marrow-1901-M            M     110288  \n",
       "A-Crane-Maggie-1893-M               M      28628  \n",
       "A-Davis-Life_Iron_mills-1861-F      F      18789  \n",
       "A-Dreiser-Sister_Carrie-1900-M      M     194062  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "\n",
    "text_dir = '../Data/Texts/'\n",
    "corpus = PlaintextCorpusReader(text_dir, '.*\\.txt')\n",
    "\n",
    "# A function to turn fileids into a table of metadata\n",
    "def parse_fileids(fileids):\n",
    "    '''Takes a list of file names formatted like A-Cather-Antonia-1918-F.txt.\n",
    "       Returns a pandas dataframe of derived metadata.'''\n",
    "    import pandas as pd\n",
    "    meta = {}\n",
    "    for fileid in fileids:\n",
    "        file = fileid.strip('.txt') # Get rid of file suffix\n",
    "        fields = file.split('-') # Split on dashes\n",
    "        fields[2] = fields[2].replace('_', ' ') # Remove underscore from titles\n",
    "        fields[3] = int(fields[3])\n",
    "        meta[file] = fields\n",
    "    metadata = pd.DataFrame.from_dict(meta, orient='index') # Build dataframe\n",
    "    metadata.columns = ['nation', 'author', 'title', 'pubdate', 'gender'] # Col names\n",
    "    return metadata.sort_index() # Note we need to sort b/c datframe built from dictionary\n",
    "\n",
    "def collect_stats(corpus):\n",
    "    '''Takes an NLTK corpus as input. \n",
    "       Returns a pandas dataframe of stats indexed to fileid.'''\n",
    "    import nltk\n",
    "    import pandas as pd\n",
    "    stats = {}\n",
    "    for fileid in corpus.fileids():\n",
    "        word_count = len(corpus.words(fileid))\n",
    "        stats[fileid.strip('.txt')] = {'wordcount':word_count}\n",
    "    statistics = pd.DataFrame.from_dict(stats, orient='index')\n",
    "    return statistics.sort_index()\n",
    "\n",
    "books = parse_fileids(corpus.fileids())\n",
    "stats = collect_stats(corpus)\n",
    "books = books.join(stats)\n",
    "books.index.set_names('file', inplace=True)\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and parse NER-tagged files\n",
    "\n",
    "The taged NER files are in the `..Data/NER/` directory. We need a function that will parse each one and return just the locations for further processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_loc(line):\n",
    "    '''Takes a string of NER output. \n",
    "       Returns a location if found, else None.'''\n",
    "    line = line.split('\\t')\n",
    "    try:\n",
    "        if line[1] == 'LOCATION':\n",
    "            return line[0]\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def ingest_ner(f):\n",
    "    '''Take a file handle for an NER output file.\n",
    "       Returns a dict of locations and counts.'''\n",
    "    from collections import defaultdict\n",
    "    locations = defaultdict(lambda: 0)\n",
    "    for line in f:\n",
    "        loc = get_loc(line)\n",
    "        if loc:\n",
    "            locations[loc] += 1\n",
    "    return locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "ner_dir = '../Data/NER/'\n",
    "\n",
    "files_list =[]\n",
    "locs_list = []\n",
    "occurs_list = []\n",
    "\n",
    "for fileid in sorted(corpus.fileids()):\n",
    "    file = os.path.join(ner_dir, fileid)\n",
    "    with open(file) as f:\n",
    "        locations = ingest_ner(f)\n",
    "        for loc in sorted(locations, key=locations.get, reverse=True):\n",
    "            files_list.append(fileid.strip('.txt'))\n",
    "            locs_list.append(loc)\n",
    "            occurs_list.append(locations[loc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            occurs\n",
      "count  3439.000000\n",
      "mean      4.178831\n",
      "std      15.361014\n",
      "min       1.000000\n",
      "25%       1.000000\n",
      "50%       1.000000\n",
      "75%       2.000000\n",
      "max     495.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>location</th>\n",
       "      <th>occurs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-Cather-Antonia-1918-F</td>\n",
       "      <td>Black Hawk</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-Cather-Antonia-1918-F</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-Cather-Antonia-1918-F</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-Cather-Antonia-1918-F</td>\n",
       "      <td>Omaha</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A-Cather-Antonia-1918-F</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      file    location  occurs\n",
       "0  A-Cather-Antonia-1918-F  Black Hawk      21\n",
       "1  A-Cather-Antonia-1918-F    Nebraska      16\n",
       "2  A-Cather-Antonia-1918-F    Virginia      13\n",
       "3  A-Cather-Antonia-1918-F       Omaha      10\n",
       "4  A-Cather-Antonia-1918-F     Chicago      10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'file': files_list, \n",
    "     'location': locs_list,\n",
    "     'occurs': occurs_list}\n",
    "geo = pd.DataFrame(d)\n",
    "print(geo.describe())\n",
    "geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14371"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of named location occurrences in corpus\n",
    "geo.occurs.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>location</th>\n",
       "      <th>occurs</th>\n",
       "      <th>nation</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>pubdate</th>\n",
       "      <th>gender</th>\n",
       "      <th>wordcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-Cather-Antonia-1918-F</td>\n",
       "      <td>Black Hawk</td>\n",
       "      <td>21</td>\n",
       "      <td>A</td>\n",
       "      <td>Cather</td>\n",
       "      <td>Antonia</td>\n",
       "      <td>1918</td>\n",
       "      <td>F</td>\n",
       "      <td>97574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-Cather-Antonia-1918-F</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>16</td>\n",
       "      <td>A</td>\n",
       "      <td>Cather</td>\n",
       "      <td>Antonia</td>\n",
       "      <td>1918</td>\n",
       "      <td>F</td>\n",
       "      <td>97574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-Cather-Antonia-1918-F</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>13</td>\n",
       "      <td>A</td>\n",
       "      <td>Cather</td>\n",
       "      <td>Antonia</td>\n",
       "      <td>1918</td>\n",
       "      <td>F</td>\n",
       "      <td>97574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-Cather-Antonia-1918-F</td>\n",
       "      <td>Omaha</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>Cather</td>\n",
       "      <td>Antonia</td>\n",
       "      <td>1918</td>\n",
       "      <td>F</td>\n",
       "      <td>97574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A-Cather-Antonia-1918-F</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>Cather</td>\n",
       "      <td>Antonia</td>\n",
       "      <td>1918</td>\n",
       "      <td>F</td>\n",
       "      <td>97574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      file    location  occurs nation  author    title  \\\n",
       "0  A-Cather-Antonia-1918-F  Black Hawk      21      A  Cather  Antonia   \n",
       "1  A-Cather-Antonia-1918-F    Nebraska      16      A  Cather  Antonia   \n",
       "2  A-Cather-Antonia-1918-F    Virginia      13      A  Cather  Antonia   \n",
       "3  A-Cather-Antonia-1918-F       Omaha      10      A  Cather  Antonia   \n",
       "4  A-Cather-Antonia-1918-F     Chicago      10      A  Cather  Antonia   \n",
       "\n",
       "   pubdate gender  wordcount  \n",
       "0     1918      F      97574  \n",
       "1     1918      F      97574  \n",
       "2     1918      F      97574  \n",
       "3     1918      F      97574  \n",
       "4     1918      F      97574  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo = geo.join(books, on='file')\n",
    "geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "places = geo.groupby('location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location\n",
       "ASIA                  1\n",
       "AUGUSTUS MELMOTTE     1\n",
       "Abchurch Lane        27\n",
       "Abingdon              1\n",
       "Abingdon Street       1\n",
       "Name: occurs, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places.occurs.aggregate(np.sum).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location\n",
       "ASIA                 1\n",
       "AUGUSTUS MELMOTTE    1\n",
       "Abchurch Lane        1\n",
       "Abingdon             1\n",
       "Abingdon Street      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places.occurs.size().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            occurs      volumes\n",
      "count  2365.000000  2365.000000\n",
      "mean      6.076533     1.454123\n",
      "std      30.206909     1.580908\n",
      "min       1.000000     1.000000\n",
      "25%       1.000000     1.000000\n",
      "50%       1.000000     1.000000\n",
      "75%       3.000000     1.000000\n",
      "max    1042.000000    23.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurs</th>\n",
       "      <th>volumes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ASIA</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUGUSTUS MELMOTTE</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abchurch Lane</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abingdon</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abingdon Street</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   occurs  volumes\n",
       "location                          \n",
       "ASIA                    1        1\n",
       "AUGUSTUS MELMOTTE       1        1\n",
       "Abchurch Lane          27        1\n",
       "Abingdon                1        1\n",
       "Abingdon Street         1        1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place_counts = pd.DataFrame(places.occurs.aggregate(np.sum))\n",
    "place_counts['volumes'] = places.occurs.size()\n",
    "print(place_counts.describe())\n",
    "place_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurs</th>\n",
       "      <th>volumes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>441.000000</td>\n",
       "      <td>441.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25.795918</td>\n",
       "      <td>3.031746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>66.475861</td>\n",
       "      <td>3.161399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1042.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            occurs     volumes\n",
       "count   441.000000  441.000000\n",
       "mean     25.795918    3.031746\n",
       "std      66.475861    3.161399\n",
       "min       3.000000    1.000000\n",
       "25%       7.000000    1.000000\n",
       "50%      11.000000    2.000000\n",
       "75%      22.000000    4.000000\n",
       "max    1042.000000   23.000000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookups = place_counts[(place_counts['occurs']>5) | (place_counts['volumes']>2)]\n",
    "lookups.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurs</th>\n",
       "      <th>volumes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abchurch Lane</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adele</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Africa</th>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albany</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               occurs  volumes\n",
       "location                      \n",
       "Abchurch Lane      27        1\n",
       "Adele              14        1\n",
       "Africa             36        8\n",
       "Alabama             6        1\n",
       "Albany              7        4"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters for geocoding clients\n",
    "# NOTE: Per-second query rates will quickly use up daily API quota.\n",
    "#   Need to be careful not to exceed daily quota\n",
    "\n",
    "import googlemaps\n",
    "\n",
    "gc_rate  =     50 # Geocoding queries per second\n",
    "pl_rate  =      5 # Places queries per second\n",
    "api_key_file = '/Users/mwilkens/Google Drive/Private/google-geo-api-key.txt'\n",
    "\n",
    "# Get API key from file\n",
    "try:\n",
    "    api_key = open(api_key_file).read().strip()\n",
    "except:\n",
    "    sys.exit('Cannot get Google geocoding API key. Exiting.')\n",
    "\n",
    "gc_client = googlemaps.Client(key=api_key, queries_per_second=gc_rate) # For Places API\n",
    "pl_client = googlemaps.Client(key=api_key, queries_per_second=pl_rate) # For Geocoding API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function to get place_ids from strings\n",
    "def get_placeid(string, api_client):\n",
    "    '''Takes a string and an established googlemaps places API client.\n",
    "       Returns first place_id associated with that string.\n",
    "       If not place_id found, returns \"ZERO_RESULTS\" or None, depending on result status code.'''\n",
    "    try:\n",
    "        place = api_client.places(string)\n",
    "        status = place['status']\n",
    "        if status == 'OK':\n",
    "            place_id = place['results'][0]['place_id']\n",
    "        elif status == 'ZERO_RESULTS':\n",
    "            place_id = None\n",
    "        else:\n",
    "            place_id = None\n",
    "    except:\n",
    "        place_id = None\n",
    "    return place_id\n",
    "\n",
    "def process_id(placeid, api_client):\n",
    "    '''Takes a Google place_id and an established googlemaps geocoding API client.\n",
    "        Looks up and parses geo data for placeid.\n",
    "        Returns int code on error, else dictionary of geo data keyed to placeid.\n",
    "    '''\n",
    "    # Define all variables, initial to None\n",
    "    formatted_address = None\n",
    "    location_type = None\n",
    "    country_long = None\n",
    "    country_short = None\n",
    "    admin_1_long = None\n",
    "    admin_1_short = None\n",
    "    admin_2 = None\n",
    "    locality = None\n",
    "    colloquial_area = None\n",
    "    continent = None\n",
    "    natural_feature = None\n",
    "    point_of_interest = None\n",
    "    lat = None\n",
    "    lon = None\n",
    "    partial = None\n",
    "    \n",
    "    # Perform reverse geocode. Note this needs googlemaps v 2.4.2-dev0 or higher\n",
    "    try:\n",
    "        data = gc_client.reverse_geocode(placeid)\n",
    "    except:\n",
    "        return 1 # Problem with geocoding API call\n",
    "    \n",
    "    # Use the first result. Should only be one when reverse geocoding with place_id.\n",
    "    try:\n",
    "        data = data[0]\n",
    "        formatted_address = data['formatted_address']\n",
    "        location_type = data['types'][0]\n",
    "        lat = data['geometry']['location']['lat']\n",
    "        lon = data['geometry']['location']['lng']\n",
    "        try:\n",
    "            partial = result['partial_match']\n",
    "        except:\n",
    "            partial = False\n",
    "    except:\n",
    "        print(\"   Bad geocode for place_id %s\" % (placeid))\n",
    "        return 2 # Problem with basic geocode result\n",
    "    \n",
    "    try:\n",
    "        for addr_comp in data['address_components']:\n",
    "            comp_type = addr_comp['types'][0]\n",
    "            if comp_type == 'locality':\n",
    "                locality = addr_comp['long_name']\n",
    "            elif comp_type == 'country':\n",
    "                country_long = addr_comp['long_name']\n",
    "                country_short = addr_comp['short_name']\n",
    "            elif comp_type == 'administrative_area_level_1':\n",
    "                admin_1_long = addr_comp['long_name']\n",
    "                admin_1_short = addr_comp['short_name']\n",
    "            elif comp_type == 'administrative_area_level_2':\n",
    "                admin_2 = addr_comp['long_name']\n",
    "            elif comp_type == 'colloquial_area':\n",
    "                colloquial_area = addr_comp['long_name']\n",
    "            elif comp_type == 'natural_feature':\n",
    "                natural_feature = addr_comp['long_name']\n",
    "            elif comp_type == 'point_of_interest':\n",
    "                point_of_interest = addr_comp['long_name']\n",
    "            elif comp_type == 'continent':\n",
    "                continent = addr_comp['long_name']\n",
    "    except:\n",
    "        return 3 # Problem with address components\n",
    "     \n",
    "    ### Code to build results dictionary here\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [carto]",
   "language": "python",
   "name": "Python [carto]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0rc4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
